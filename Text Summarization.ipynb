{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a606fdfd",
   "metadata": {},
   "source": [
    "Setting Default Cache to specified path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9ec2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"D:/transformer_cache/\"\n",
    "os.environ['HF_DATASETS_CACHE'] = \"D:/transformer_cache/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730fc3f",
   "metadata": {},
   "source": [
    "Importing the cnn_dailymail dataset and printing its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8e9ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac12443",
   "metadata": {},
   "source": [
    "Printing first 500 characters of the article at index [1] and its corresponding summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f21dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baead602",
   "metadata": {},
   "source": [
    "We are restricting the input size to 2000 characters and we store a sample input text at index [1] in \"sample text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614ddadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b143a",
   "metadata": {},
   "source": [
    "Creating our tokenizer that splits the input text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7bf2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62ad43",
   "metadata": {},
   "source": [
    "We use the first three sentences as our summary baseline to compare the generated summaries against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2107370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23785e",
   "metadata": {},
   "source": [
    "Loading the GPT-2 model. The model can be used to generate summaries by appending a TL;DR at the end of the input text, which is done in the below code. \n",
    "Max generated summary length is set to 512. clean_up_tokenization removes extra spaces generated during tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa93b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bad34",
   "metadata": {},
   "source": [
    "Loading the T5 model and creating a smiliar pipeline.\n",
    "T5 is a text to text model and can be used for summarization by providing the input as \"summarize: <ARTICLE>\". We can directly laod T5 for summarization using pipeline() without worrying about formatting the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a427e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5896c",
   "metadata": {},
   "source": [
    "Loading the BART model and creating a similiar pipeline.\n",
    "BART uses an encoder-decoder architecture and is trained to reconstruct corrupted inputs.\n",
    "We use the facebook/bart-large-cnn checkpoint, which has been fine-tuned on the CNN/daily mail dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0554a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c5d2a",
   "metadata": {},
   "source": [
    "Loading the PEGASUS model. It has an encoder-decoder architecture. Its pre-training objective is to reconstruct masked sentences.\n",
    "The model has the <n> token for newlines hence sent_tokenize(), which splits into sentences is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70cba4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00bfba",
   "metadata": {},
   "source": [
    "We print the summaries stored in dataset, the baseline summary and the summaries generated by GPT-2, T5, BART and PEGASUS and compare them qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766636f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n",
      "\n",
      "GPT2\n",
      "To get to the jail, you go up a flight of stairs, pass a metal detector, and go down a hall.\n",
      "The inmates are so scared that they'll be thrown in jail for not turning up your appointment.\n",
      "The first room to the right is where the mentally ill inmates are housed, and the next room to the bottom is where the regular inmates go.\n",
      "At the end,\n",
      "\n",
      "T5\n",
      "mentally ill inmates are housed on the ninth floor of a florida jail .\n",
      "most face drug charges or charges of assaulting an officer .\n",
      "judge says arrests often result from confrontations with police .\n",
      "one-third of all people in Miami-dade county jails are mental ill .\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"<n>The ninth floor is where they're held until they're ready to appear in court.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "They end up on the ninth floor severely mentally disturbed .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(\"ARTICLE\")\n",
    "#print(dataset[\"train\"][1][\"article\"][:2000])\n",
    "#print(\"\")\n",
    "print(\"GROUND TRUTH\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34062b2",
   "metadata": {},
   "source": [
    "We now compare the summaries generated using the ROUGE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b7b09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23300\\2048908469.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge_metric = load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd5fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (4.66.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk->rouge_score) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c48dd",
   "metadata": {},
   "source": [
    "We compare the models using the ROUGE metric on the CNN/dailymail dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5cb537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.271186  0.051724  0.152542   0.271186\n",
       "t5        0.382979  0.130435  0.255319   0.382979\n",
       "bart      0.475248  0.222222  0.316832   0.415842"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "rouge_metric = load_metric(\"rouge\",trust_remote_code=True)\n",
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0bd49",
   "metadata": {},
   "source": [
    "We evaluate the baseline using ROUGE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ae02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,column_text=\"article\",column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "    references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0753ff4",
   "metadata": {},
   "source": [
    "We use only 500 data points to evaluate the baseline as doing so on the entire dataset is computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c71ba065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.388588</td>\n",
       "      <td>0.168604</td>\n",
       "      <td>0.242256</td>\n",
       "      <td>0.351425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.388588  0.168604  0.242256   0.351425"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(500))\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c596f",
   "metadata": {},
   "source": [
    "We now evaluate the PEGASUS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a0b0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, \n",
    "                               batch_size=16, device=device, \n",
    "                               column_text=\"article\", \n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        \n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device), \n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n",
    "                                clean_up_tokenization_spaces=True) \n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "        \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce5e1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "#device=\"cpu\"\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd35d572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 63/63 [4:05:47<00:00, 234.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.012641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.012722  0.000559  0.012589   0.012641"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "#device=\"cpu\"\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "#score = evaluate_summaries_pegasus(test_sampled, rouge_metric, \n",
    "#                                   model, tokenizer, batch_size=8)\n",
    "#rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "#pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_input \n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd3463",
   "metadata": {},
   "source": [
    "# Training a Summarization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de71ee4",
   "metadata": {},
   "source": [
    "We use the SAMSum dataset developed by Samsung, which consists of a collection of dialogues along with brief summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf3ef1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\USER\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\samsum\\f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e (last modified on Wed Jul  3 19:21:09 2024) since it couldn't be found locally at samsum, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [14732, 819, 818]\n",
      "Features: ['id', 'dialogue', 'summary']\n",
      "\n",
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\",trust_remote_code=True)\n",
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc2668",
   "metadata": {},
   "source": [
    "We evaluate PEGASUS on SAMSum dataset BEFORE fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "325e211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "#device=\"cpu\"\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3225b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 103/103 [6:15:02<00:00, 218.47s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rouge_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m rouge_metric \u001b[38;5;241m=\u001b[39m load_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m,trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate_summaries_pegasus(dataset_samsum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m], rouge_metric, model,\n\u001b[0;32m      4\u001b[0m tokenizer, column_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m column_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, score[rn]\u001b[38;5;241m.\u001b[39mmid\u001b[38;5;241m.\u001b[39mfmeasure) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrouge_names\u001b[49m)\n\u001b[0;32m      7\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rouge_names' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "rouge_metric = load_metric(\"rouge\",trust_remote_code=True)\n",
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n",
    "tokenizer, column_text=\"dialogue\",\n",
    "column_summary=\"summary\", batch_size=8)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e82b6",
   "metadata": {},
   "source": [
    "ROUGE scores before fine-tuning on SAMSum dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dc6e7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.015588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.015564  0.000294  0.015572   0.015588"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5eaf8b",
   "metadata": {},
   "source": [
    "# Fine-tuning PEGASUS on SAMSum dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c21e46",
   "metadata": {},
   "source": [
    "Plotting dialogue and summary token lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c440b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03cde4d",
   "metadata": {},
   "source": [
    "We convert the input to tokens. We set max token length for dialogues and summaries to 1024 and 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59024f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4930a5bb7a44e3a468cba309e85670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n",
    "        truncation=True)\n",
    "        return {\"input_ids\": input_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "        \"labels\": target_encodings[\"input_ids\"]}\n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n",
    "batched=True)\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd34570",
   "metadata": {},
   "source": [
    "We define the data collator. The data collator collects all tensors from the batch and stacks them up. It shifts the summary labels at the decoder side by 1 to implement \"teacher forcing\". In addition, ignoring of padding tokens is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfd5a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57eef4c",
   "metadata": {},
   "source": [
    "We now carry out training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95cde7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "weight_decay=0.01, logging_steps=10, push_to_hub=True,\n",
    "evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "gradient_accumulation_steps=16)\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "# training_args = TrainingArguments(\n",
    "# output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "# per_device_train_batch_size=1,\n",
    "# weight_decay=0.01, logging_steps=10, push_to_hub=True,\n",
    "# evaluation_strategy='steps', eval_steps=500, save_steps=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7a0c52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab1358dc9a2498697e1e36e34fef8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "579d6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "train_dataset=dataset_samsum_pt[\"train\"],\n",
    "eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad56f672",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 4.00 GiB total capacity; 3.43 GiB already allocated; 0 bytes free; 3.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate_summaries_pegasus(\n\u001b[0;32m      3\u001b[0m dataset_samsum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m], rouge_metric, trainer\u001b[38;5;241m.\u001b[39mmodel, tokenizer,\n\u001b[0;32m      4\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, column_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, score[rn]\u001b[38;5;241m.\u001b[39mmid\u001b[38;5;241m.\u001b[39mfmeasure) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1923\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[1;32m-> 1923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1930\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2274\u001b[0m ):\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:3324\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3322\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:2134\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2134\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 4.00 GiB total capacity; 3.43 GiB already allocated; 0 bytes free; 3.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "score = evaluate_summaries_pegasus(\n",
    "dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
    "batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd6ec3",
   "metadata": {},
   "source": [
    "The training could not be implemented due to lack of GPU resources. However, it is expected that there would be an improvement in the ROUGE score of the model that was fine-tuned on the SAMSum dataset, over the PEGASUS model before fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2e059",
   "metadata": {},
   "source": [
    "ROUGE scores AFTER fine-tuning."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9ee084f9",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949bd17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
